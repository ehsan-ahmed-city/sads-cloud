# sads-cloud
Secure and Auditable Data Storage in the Cloud

# Github repo:
https://github.com/ehsan-ahmed-city/sads-cloud

# Video Demo
https://youtu.be/XFDHSSFjy-4
Github didn't let us push the file as it was too big so uploaded it to youtube.


## Overview
SADS-Cloud is a cloud-based secure data outsourcing system that demonstrates how sensitive data can be stored,processed and retrieved in the cloud without fully trusting the cloud provider.

The project follows the original proposal and research foundations while extending them with practical cloud-native features such as behaviour-based trust monitoring, encrypted data clustering and indexing

The system is implemented using AWS services and is a Streamlit-based app.


## Architecture Summary

The system is split into three main components:

### 1 Authentication/ Trust Centre  
Asad Arshad

- AWS cognito-based authentication
- Immutable login event logging in amazon S3
- Behaviour based suspicious login detection by requirements i made based on paper
- Serverless alerting using AWS lambda and SNS
- Aggressive detection to minimise false negatives



### 2 Encryption upload and compression pipeline and EMR attempt  
Ehsan Ahmed

- Client-side LZMA compression
- Chunk-based SALSA20 encryption
- Secure upload to S3
- Attempted parallel processing through EMR serverless, with logging but is limited to RAW file uplaod as beyond that couldn not be done because of dependencies such asubuntu
- Helped wiring functions to streamlit UI


### 3 Storage, Clustering and Indexing  
**Author:** Zain Butt

- DBSCAN clustering on encrypted metadata
- Fractal Index Tree for fast lookup and retrieval
- Cost-aware access by minimising S3 scans
- Secure reconstruction and integrity verification



## Cloud usage justification

Quik note that screenshots of AWS services are in /awsScreenshots for proof; the services only display on AWS console so screenshots were uploaded to show it

This project uses cloud services because they are necessary, the technologies we used here were::

- **Amazon S3**: used for storage as it's a durable,scalable object storage for encrypted data and audit logs  
- **AWS Cognito**: created users for all of us, placed our users in a group, managed authentication and token verification  
- **AWS Lambda**: serverless alerting for sus behaviour.
- **AWS SNS**: real-time email notifications which is sent to selected emails such as an admin 
- **EMR Serverless**: big data style batch processing (but limited to only raw file supload).
-  **AWS IAM**: IAM was used to setup permissions for user to access data and setting up


## IAM and Security Configuration

Since our project makes heavy use of AWS services, IAM configuration was performed directly in AWS Console for security practice and to avoid committing sensitive infra or credentials to the repo

### IAM Roles Overview

IAM roles are separated by responsibility, since there's 3 of us we created a user group called SADS-Cloud-Dev with permission policies whcih enabled us ot interact with aws services

---

### 1. Lambda Execution Role for suspicious login alerts

`sads-lambda-suspicious-login-role`

**what it does:**  
Allows the Lambda function to process login events generated by the Trust Centre and publish alerts when suspicious behaviour is detected
(/awsScreenshots/lambda-suspicious-login.png)

permissions:
- `s3:GetObject`  
  Read immutable login log objects from  
  `sads-raw-data/trust-centre/logins/`
- `sns:Publish`  
  send alert notifications to the `sads-suspicious-login`

- `logs:CreateLogGroup`, `logs:CreateLogStream`, `logs:PutLogEvents`  
  the event logs to amazon CloudWatch

**Reason used:**  
This role is minimal scope to event processing and alerting only, so it cannot modify logs or access unrelated S3 objects

---

### 2. EMR Serverless Execution Role

**what it does:**  
Allows EMR serverless jobs to perform parallel encryption and storage of uploaded data

Permissions:
- `s3:GetObject` on `raw/`  
- `s3:PutObject` on `encrypted/`  
- CloudWatch logging perms

**Reason used:**  
well ir was supposed to support batch-style encryption whih can scale for big data while ensuring EMR jobs can only read raw input data and write encrypted outputs. There's no direct access to unrelated buckets/prefixes



## Cognito for users identity and ownership in S3

**What it does:**  
AWS Cognito is used to manage user identities for the system and to show data owners and data users. Like when the email sns for the login came through, the data owner recieved it.
/awsScreenshots/cogniUser.png

Each authenticated user is goven a unique cognito user ID, which is then used consistently across the system to scope storage, track behaviour and enforce what they can access

**How it used in the project:**
- Test users are created and managed in an AWS Cognito user pool
- On login, the Cognito access token is verified by the application
- The extracted `user_id` becomes the identifier for the storage paths (like encrypted,raw,fit,cluster), immutable login audit logs, behaviour analysis

The s3 model: 
Each user only interacts with objects under their own prefix in the `sads-raw-data` bucket, shown in the dmeo but an example would be user1234: 'Buckets/sads-raw-data/encrypted/user1234/'

This models common multi-user cloud environment where users do not share storage namespaces

Security properties provided:
- Prevents users from accessing or overwriting other users’ data
- Allows auditability and anomaly detection and users can be identified

**Reason used:**  
Cognito allows identity management to be handled by a managed cloud service separating authentication concerns from data processing logic from the app or S3. This aligns with the project’s trust model and enables a realistic, secure cloud-based demo without implementing a custom authentication system.


### IAM Design choice

IAM roles are intentionally separated across the following responsibilities:
- Authentication  
- Data processing  
- alerting  

which improves:
- security as theres minimal permissions per component  
- Audit logs as there's clear ownership of actions  
- Isolates faults becauase compromised components cannot escalate privileges  

This design aligns with the project’s trust model, where cloud components are assumed to be honest and are therefore tightly constrained through IAM policies.


Cost and resource usage are minimised by:
- Chunked encryption
- Metadata-only clustering
- Indexed retrieval instead of full scans
- Serverless components where appropriate

---

### AWS Lambda for login alert

The screenshot `awsScreenshots/lambda-suspicious-login.png` shows the deployed AWS Lambda function which implements the serverless alerting component of the trust centre

It's automatically triggered by S3 object creation events in `trust-centre/logins/`. (a screenshot in awsScreenshots/s3LoginBucketDates) Each object represents an immutable login event written by the
authentication layer.

The function: reads newly created login log objects from S3
- parses the login decision produced by the anomaly detection logic
- If the login marked as suspicious, publishes an alert message to AWS SNS
- If the login is normal, nothing else happens

The screenshot shows:
- The Lambda function deployed and active in AWS
- Integration with S3 as an event source
- The serverless nature of the alerting pipeline (no persistent infrastructure)

**Why Lambda is used:**
Lambda allows suspicious login alerts to be handled asynchronously and automatically, without
adding latency to the authentication flow. This matches the project’s trust model, where monitoring
and enforcement are decoupled from user-facing operations.

**Security and design properties:**
- The function runs under a least privilege IAM role
- It has read-only access to login logs

- It can't modify data or access encrypted user content
- Alert delivery is handled via SNS to the Data Owner, ensuring reliability and logging for each user

This Lambda-based design demonstrates a realistic cloud security pattern used in production systems,
where detection, alerting, and response are implemented as independent serverless components.


## Research

The project is based on research into secure cloud data outsourcing and trust management systems.
This ncludes:
- Behaviour based login anomaly detection such as based on custom rules
- Serverless alerting pipeline
- Practical encrypted data clustering
- Cost-aware indexing and retrieval, saves time and resources
- End-to-end system with audit logging

## Mapping to project proposal

Proposal concept and the implementation

User authentication & trust is implemented through AWS Cognito and Trust Centre 
Immutable audit logs was implemented with append-only S3 login logs
Anomaly detection was implemented with rule-based behaviour analysis

Secure outsourcing was implemented through client-side encryption before cloud storage
Encrypted data management  Metadata-only clustering & indexing

Trust enforcement was created through Lambda and SNS alerts


---

## Design Decisions and Limitations

### EMR Serverless
EMR Serverless was explored to evaluate whether encryption and storage
operations could be offloaded to a scalable big-data env.

While job submission, logging and RAW file upload were added successfully, execution was limited by native dependency
constraints (during execution the job encounters limitations due to native linux/Ubuntu dependencies within EMR. this prevented certain libs from loading correctly without unmanaged clusters) The EMR workflow successfully supports job submission, scheduling, logging, and RAW file upload, as shown in the one of the screenshots(`awsScreenshots/emrDefunc.png`).

Rather than introducing insecure workarounds or unmanaged clusters,
Rather than introducing insecure or non-portable workarounds, this limitation was documented and the design kept secure
client-side encryption as the main approach of what we based our solution from our research paper

## SageMaker consideration and design Decision

Amazon Sagemaker was initially considered in the project proposal as a
potential platform for ml-based anomaly detection on login behaviour but
during implementation, this was not included for a few reasons:

- The project operates on a limited and controlled dataset, making
  rule-based detection more appropriate
- The suspicious login logic is explainable, auditable and aligns with the trust model described in the research
- Using SageMaker would introduce unnecessary cost and operational complexity without improving detection quality for this use case as students
- Since the research focus emphaisses on trust enforcement and auditability rather than ML decision-making, it wasn't high priority during development

Instead, the system implements feature extraction and behavioural rules
(time-of-day, frequency,failures, time since last login), which can be directly extended to ML models in future work

It was a practical trade-off between scalability, how we can interpret it and system complexity.


### No Docker/Kubrenetes
Containers was excluded to keep the focus on security, trust modelling, auditability, cloud-native managed services



## Demo

The project demo vid includes a Streamlit console that showed:
- user authentication for verified users(managed in cognito)
- file upload and encryption
- clustering and indexing
- secure retrieval and integrity verification
- monitoring of cloud-side artefacts in S3

## How to Run it

This project is demonstrated through a Streamlit-based web app

### Prereqs
- Python 3.12+ (we used 3.12.4)
- AWS credentials configured and access to the configured AWS services (like IAM, Cognito, S3 and Lambda)

### Running the app
```bash
pip install -r requirements.txt
streamlit run ui/app.py


---


## Repository Structure

- `auth/` — Cognito authentication, token verification and login handling
- `trust_centre/` — Login logging, suspicious behaviour detection logic

- `encryption/` — SALSA20 encryption logic
- `compression/` — LZMA compression 
- `storage/` — S3 client (what we used for storage)

- `clustering/` — DBSCAN clustering of encrypted metdata
- `indexing/` — Fractal index tree for efficient lookup

- `lambda/` — AWS Lambda code for suspicious login alerts

- `emr/` — EMR Serverless batch encryption attempt

- `ui/` — The streamlit demo appl

- `awsScreenshots/` — Screenshots of deployed AWS resources that may have not been visible in demo


## Contributors

Equal contribution

- **Asad Arshad** — Authentication, Trust Centre, anomaly detection and  AWS Lambda, alerting 
- **Ehsan Ahmed** — AWS user setup in cognito, AWS IAM, Encryption, compression, cloud operations integrating, UI integration  
- **Zain Butt** — Clustering, indexing, lookup, retrieval optimisation  


